data(ldt)
summary(ldt$Freq)
plot(sort(ldt$Freq, decreasing = TRUE), type = "b", main = "Zipf's Law", ylab = "Word Frequency")
hist(ldt$Freq, main = "Histogram of Word Frequencies", xlab = "Word Frequency in a Corpus", ylab = "Relative Frequency in the Sample")
plot(density(ldt$Freq), main = "Density Plot of Word Frequencies", xlab = "Word Frequency in a Corpus")
qqnorm(ldt$Freq)
plot(density(log(ldt$Freq)), main = "Density Plot of Word Frequencies", xlab = "Word Frequency in a Corpus")
curve(max(mydata$freq, na.rm = T)/x, from = 1, to = 3000, col = "red", add = T)
sort(mydata$freq, dec = T)
sort(data$freq, dec = T)
sort(ldt$freq, dec = T)
mydata <- ldt$Freq[!na.rm]
mydata <- ldt$Freq[ldt$Freq != !na.rm]
mydata <- ldt$Freq[ldt$Freq != NA]
sort(mydata$freq, dec = T)
sort(mydata, dec = T)
mydata <- ldt$Freq[ldt$Freq != NA]
plot(sort(mydata, dec = T))
plot(sort(mydata, dec = T))
ldt$Freq
summary(pym_high$conc)
data(pym_high)
library(Rling)
library(ggplot2)
data("pym_high")
data("pym_low")
qqnor(pym_high$conc)
qqnorm(pym_high$conc)
qqline(pym_high$conc)
plot(density(pym_high$conc))
stripchart(list(pym_high$conc, pym_low$conc), main = "Distribution of Concreteness Scores", group.names = c("high", "low"), method = "jitter", xlim = c(1, 7))
rug(pym_high$conc, side = 1)
rug(pym_low$conc, side = 3)
shapiro.test(pym_high$conc)
shapiro.test(pym_high$assoc)
plot(density(pym_low$conc))
plot(density(pym_high$conc))
wilcox.test(pym_high$conc, pym_low$conc, correct = FALSE, conf.int = TUE)
wilcox.test(pym_high$conc, pym_low$conc, correct = FALSE, conf.int = TRUE)
diff <- rnorm(50, -1.35, 1.27)
head(diff)
nn <- pym_high$assoc + diff
head(nn)
nn <- round(nn, 2)
shapiro.test(diff)
t.test(pym_high$assoc, nn, alternative = "greater", paired = TRUE)
library(Rling)
data(pym_high)
data(pym_low)
plot(density(pym_low$assoc),xlim=c(2,11),xlab="Assoc",main="Density")
lines(density(pym_high$assoc),lty=2,col="red")  # looks a little bimodal
rug(pym_high$assoc,col="red",lwd=2)
rug(pym_low$assoc,col="black",lwd=2)
shapiro.test(pym_high$assoc)  # but (barely) passes the normality test
shapiro.test(pym_low$assoc)
t.test(pym_high$assoc,pym_low$assoc)
wilcox.test(pym_high$assoc,pym_low$assoc)  # a different answer
wilcox.test(assoc~freq,data=pym)  # formula notation --> does association vary as a function of the different frequency groups? Find these variables in my dataset
pym_high$freq <- "high"  # add a column in both data sets
pym_low$freq <- "low"
pym <- rbind(pym_high,pym_low)  # combine them
pym$freq <- factor(pym$freq)
wilcox.test(assoc~freq,data=pym)  # formula notation --> does association vary as a function of the different frequency groups? Find these variables in my dataset
pym$rank <- rank(pym$assoc,ties.method = "average")  # ranked by assoc
tb <- table(pym$freq)   # choose the smaller group
if (tb[1]<=tb[2]) {
targ <- names(tb)[1]
n <- tb[targ]
} else {
targ <- names(tb)[2]
n <- tb[targ]
}
m <- sum(tb)-n
W <- sum(pym$rank[pym$freq==targ])  # sum of ranks, for freq= "high"
U <- W - n*(n+1)/2
sample_U = U
?order
x = c(1,2,3)
x = c(3,1,2)
x
order(x)
sort(x)
?rank
rank(x)
setwd("~/Documents/Documents/2015-2020 Berkeley/G1/LING160 - Quantitative Methods in Linguistics/Homework")
read.delim(file = "cherokeeVOT.txt")
cherokee <- read.delim(file = "cherokeeVOT.txt")
cherokee
c1971 <- subset(cherokee, year = '1971')
c1971
rank(c1971, ties.method = "random")
?rank
sort(c1971)
rank(c1971$VOT)
rank(c1971$VOT, ties.method = "random")
sort(c1971$VOT)
c1971$VOT
order(c1971$VOT)
rank(c1971$VOT, ties.method = "random")
pym$rank
pym$rank <- rank(pym$assoc,ties.method = "average")  # ranked by assoc
pym$assoc
rank(pym$assoc, ties.method = "average")
stat <- vector()
for (i in 1:5000) {
random.ranks <- sample(100)
W <- sum(random.ranks[1:50])
stat[i] <- W
}
plot(density(stat), xlim = c(0.5, 1.5), lwd = 2, col = "orange")
plot(density(stat), lwd = 2, col = "orange")
curve(dnorm(x, mean = 2500, sd = 300), from = 2000, to = 3000, add = T, lty = 2)
rnorm(50, 30, 20) -> x1
expW <- n*(m + n + 1)/2
varW <- m * n * (m + n + 1)/12
sdW <- sqrt(varW)
curve(dnorm(x, mean = expW, sd = sdW), from = 2000, to = 3000, add = T, lty = 2)
firsthalf <- sum(random.ranks[1:50])
secondhalf <- sum(random.ranks[51:100])
stat[i] <- firsthalf/secondhalf
mean(stat)
stat <- firsthalf/secondhalf
mean(stat)
plot(density(stat), lwd = 2, col = "orange")
curve(dnorm(x, mean = 1, sd = 1/(n + m)), from = 0.5, to = 1.5, add = T, lty = 2)
curve(dnorm(x, mean = 1, sd = 1/(n + m)), from = 0.5, to = 1.5, add = T, lty = 2)
curve(dnorm(x, mean = 1, sd = 10/(n + m)), from = 0.5, to = 1.5, add = T, lty = 2)
curve(dnorm(x, mean = 1, sd = 1/(n + m)), from = 0.5, to = 1.5, add = T, lty = 2)
table(stat > 1.2/length(stat))
df <- read.csv("cherokeeVOT.txt", sep = "\t")
df
attach(df)
t1971 <- subset(df, year == "1971" & Consonant == "t")
t1971
k1971 <- subset(df, year == "1971" & Consonant == "k")
plot(density(t1971))
plot(density(t1971$VOT))
plot(density(k1971$VOT), type = "dotted")
plot(density(k1971$VOT), type = "dot")
plot(density(k1971$VOT), lty = 2)
plot(density(k1971$VOT), lty = 2, add = T)
lines(density(k1971$VOT), lty = 2)
lines((k1971$VOT), lty = 2)
plot(density(pym_low$assoc),xlim=c(2,11),xlab="Assoc",main="Density")
lines(density(pym_high$assoc),lty=2,col="red")  # looks a little bimodal
lines(density(k1971$VOT), lty = 2)
plot(density(t1971$VOT))
lines(density(k1971$VOT), lty = 2)
plot(density(t1971$VOT), xlim = c(0, 250))
lines(density(k1971$VOT), lty = 2)
legend(1, 1, legend = levels(df$Consonant))
legend(0, 0, legend = levels(df$Consonant))
legend(1, 0, legend = levels(df$Consonant))
legend(50, 50, legend = levels(df$Consonant))
legend(50, 50, legend = levels(df$Consonant))
legend(10, 10, legend = levels(df$Consonant))
legend(0, 10, legend = levels(df$Consonant))
legend(1, 1, legend = levels(df$Consonant))
legend(1, 10, legend = levels(df$Consonant))
legend(1, 100, legend = levels(df$Consonant))
legend(1, 200, legend = levels(df$Consonant))
legend(1, 0.01, legend = levels(df$Consonant))
legend(1, 0.01, legend = levels(df$Consonant), lwd = c(2.5, 2.5))
legend(1, 0.01, legend = levels(df$Consonant), lty = 1:2)
legend(225, 0.015, legend = levels(df$Consonant), lty = 1:2)
legend(200, 0.015, legend = levels(df$Consonant), lty = 1:2)
legend(200, 0.015, legend = levels(df$Consonant), lty = 1:2)
plot(density(t1971$VOT), xlim = c(0, 250))
lines(density(k1971$VOT), lty = 2)
legend(200, 0.015, legend = levels(df$Consonant), lty = 1:2)
legend(210, 0.015, legend = levels(df$Consonant), lty = 1:2)
plot(density(t1971$VOT), xlim = c(0, 250))
lines(density(k1971$VOT), lty = 2)
legend(210, 0.015, legend = levels(df$Consonant), lty = 1:2)
plot(density(t1971$VOT), xlim = c(0, 250), title = "Density Graphs of VOT in 1971")
lines(density(k1971$VOT), lty = 2)
legend(210, 0.015, legend = levels(df$Consonant), lty = 1:2)
warnings()
plot(density(t1971$VOT), xlim = c(0, 250), main = "Density Graphs of VOT in 1971")
lines(density(k1971$VOT), lty = 2)
legend(210, 0.015, legend = levels(df$Consonant), lty = 1:2)
plot(density(t1971$VOT), xlim = c(0, 250), main = "Density Graphs of VOT in 1971", xlab = "VOT (ms)", ylab = "Density")
plot(density(t1971$VOT), xlim = c(0, 250), main = "Density Graphs of VOT in 1971", xlab = "VOT (ms)")
lines(density(k1971$VOT), lty = 2)
legend(210, 0.015, legend = levels(df$Consonant), lty = 1:2)
t2001 <- subset(df, year == "2001" & Consonant == "t")
k2001 <- subset(df, year == "2001" & Consonant == "k")
shapiro.test(t1971)
shapiro.test(t1971$VOT)
shapiro.test(k1971$VOT)
shapiro.test(t2001$VOT)
shapiro.test(k2001$VOT)
plot(density(t1971$VOT))
plot(density(k1971$VOT))
plot(density(t2001$VOT))
plot(density(k2001$VOT))
plot(density(k1971$VOT))
t.test(t1971, t2001)
t.test(t1971$VOT, t2001$VOT)
wilcox.test(t1971$VOT, t2001$VOT)
t.test(k1971$VOT, k2001$VOT)
wilcox.test(k1971$VOT, k2001$VOT)
wilcox.test(k1971$VOT, k2001$VOT, correct = FALSE, conf.int = TRUE)
wilcox.test(t1971$VOT, t2001$VOT)
t1971$VOT
pym$assoc
pym$rank
pym$rank <- rank(pym$assoc,ties.method = "average")  # ranked by assoc
pym$rank <- rank(pym$assoc,ties.method = "average")  # ranked by assoc
pym$assoc
pym$rank
t1971.rank <- rank(t1971$VOT, ties.method = "random")
t1971
t1971.rank
k1971.rank <- rank(k1971$VOT, ties.method = "random")
k1971.rank
sum(t1971.rank)
vot1971 <- subset(df, year = "1971")
sorted1971 <- sort(vot1971$VOT)
sort(vot1971$VOT)
rank1971 <- rank(vot1971$VOT)
rank1971
rank1971 <- rank(vot1971$VOT, ties.method = "random")
rank1971
vot1971
t1971 <- subset(df, year == "1971" & Consonant == "t")
t1971
vot1971 <- subset(df, year = "1971")
t1971
vot1971
vot1971 <- subset(df, df$year = "1971")
vot1971 <- subset(df, year = 1971)
vot1971
df[df$year == "1971"]
df[df$year == "1971", ]
vot1971 <- df[df$year == "1971", ]
sorted1971 <- sort(vot1971$VOT)
rank1971 <- rank(vot1971$VOT, ties.method = "random")
vot1971
rank1971
sorted1971 <- sort(vot1971$VOT)
rank1971 <- rank(vot1971$VOT, ties.method = "random")
vot1971
rank1971
vot1971$Rank <- rank1971
vot1971
vot1971$Rank[Consonant == "t"]
sum(vot1971$Rank[Consonant == "t"])
vot1971$Rank[Consonant == "t"]
vot1971$Rank
Consonant == "t"
vot1971$Consonant == "t"
vot1971$Rank[vot1971$Consonant == "t"]
W <- sum(vot1971$Rank[vot1971$Consonant == "t"])
W
W
?pnorm
W
length(vot1971$Rank)
tb <- table(pym$freq)   # choose the smaller group
tb
tb[1]
m
n
table(vot1971$VOT)
table(vot1971$Rank)
table(vot1971$Consonant)
names(tb)[1]
tb[targ]
tb["high"]
t_vs_k <- table(vot1971$Consonant)
t_vs_k
exp_W <- n * (m + n + 1)/2
var_W <- m * n * (m + n + 1)/12
sd_W <- sqrt(var_W)
pnorm(W, exp_W, sd_W)
wilcox.test(t1971$VOT, k1971$VOT, alternative = "less", correct = FALSE, conf.int = TRUE)
wilcox.test(k1971$VOT, k2001$VOT, correct = FALSE, conf.int = TRUE)
wilcox.test(t1971$VOT, k1971$VOT, alternative = "less", correct = FALSE, conf.int = TRUE)
pnorm(c(t1971$VOT, k1971$VOT), exp_W, sd_W)
pnorm(W, exp_W, sd_W)
pym$freq
vot1971$Consonant == "t"
setwd("~/Documents/Documents/Linguistics/Papers/Romanian Slavic Contact/RSDC/Gen15Gnv1RomFSlavF_TokenFreqOff")
source('~/Documents/Documents/Linguistics/Papers/Romanian Slavic Contact/GenDecCaseNum/analyze.R', echo=TRUE)
plot_var <- "NPL to FPL"
ggplot(df_percents, aes(x=Generation, y=nplTOfsg))+
geom_line(aes(color=Trial))+
scale_x_discrete(breaks = seq(from=1, to=max(df_percents$Generation), by=1))+
scale_y_continuous(limits=c(0,1))+
xlab("Generation") + ylab(paste("% of", plot_var))+
theme(axis.text=element_text(size=30),
axis.title=element_text(size=40, vjust=1),
plot.title=element_text(size=50),
legend.position="none")+
ggtitle(plot_var)
plot_var <- "NPL to FPL"
ggplot(df_percents, aes(x=Generation, y=nplTOfpl))+
geom_line(aes(color=Trial))+
scale_x_discrete(breaks = seq(from=1, to=max(df_percents$Generation), by=1))+
scale_y_continuous(limits=c(0,1))+
xlab("Generation") + ylab(paste("% of", plot_var))+
theme(axis.text=element_text(size=30),
axis.title=element_text(size=40, vjust=1),
plot.title=element_text(size=50),
legend.position="none")+
ggtitle(plot_var)
plot_var <- "NSG to MSG"
ggplot(df_percents, aes(x=Generation, y=nsgTOmsg))+
geom_line(aes(color=Trial))+
scale_x_discrete(breaks = seq(from=1, to=max(df_percents$Generation), by=1))+
scale_y_continuous(limits=c(0,1))+
xlab("Generation") + ylab(paste("% of", plot_var))+
theme(axis.text=element_text(size=30),
axis.title=element_text(size=40, vjust=1),
plot.title=element_text(size=50),
legend.position="none")+
ggtitle(plot_var)
plot_var <- "MSG to NSG"
ggplot(df_percents, aes(x=Generation, y=msgTOnsg))+
geom_line(aes(color=Trial))+
scale_x_discrete(breaks = seq(from=1, to=max(df_percents$Generation), by=1))+
scale_y_continuous(limits=c(0,1))+
xlab("Generation") + ylab(paste("% of", plot_var))+
theme(axis.text=element_text(size=30),
axis.title=element_text(size=40, vjust=1),
plot.title=element_text(size=50),
legend.position="none")+
ggtitle(plot_var)
setwd("~/Documents/Documents/Linguistics/Papers/Romanian Slavic Contact/RSDC/Gen15RomFSlavF_TokenFreqOff")
source('~/Documents/Documents/Linguistics/Papers/Romanian Slavic Contact/GenDecCaseNum/analyze.R', echo=TRUE)
plot_var <- "NPL to FSG"
ggplot(df_percents, aes(x=Generation, y=nplTOfsg))+
geom_line(aes(color=Trial))+
scale_x_discrete(breaks = seq(from=1, to=max(df_percents$Generation), by=1))+
scale_y_continuous(limits=c(0,1))+
xlab("Generation") + ylab(paste("% of", plot_var))+
theme(axis.text=element_text(size=30),
axis.title=element_text(size=40, vjust=1),
plot.title=element_text(size=50),
legend.position="none")+
ggtitle(plot_var)
wilcox.test(k1971$VOT, k2001$VOT, correct = FALSE, conf.int = TRUE)
pnorm(W, exp_W, sd_W)
wilcox.test(t1971$VOT, k1971$VOT, alternative = "less", correct = FALSE, conf.int = TRUE)
W
exp_W
m = 8   # number of /k/ tokens
n = 10  # number of /t/ tokens
exp_W <- n * (m + n + 1)/2
var_W <- m * n * (m + n + 1)/12
sd_W <- sqrt(var_W)
pnorm(W, exp_W, sd_W)
wilcox.test(t1971$VOT, k1971$VOT, alternative = "less", correct = FALSE, conf.int = TRUE)
W
pnorm(W, exp_W, sd_W)
wilcox.test(t1971$VOT, k1971$VOT, alternative = "less", correct = FALSE, conf.int = TRUE)
exp_W
var_W
length(vot1971$Consonant == "t")
for (i in 1:5000) {
random_ranks <- sample(length(vot1971$Rank))
W <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W
}
stat <- vector()
for (i in 1:5000) {
random_ranks <- sample(length(vot1971$Rank))
W <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W
}
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150)
lines(density(W_random), lty = 2)
stat <- vector()
for (i in 1:5000) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
lines(density(W_random), lty = 2)
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150)
lines(density(W_random), lty = 2)
lines(density(stat), lty = 2)
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150)
lines(density(stat), lty = 2)
curve(dnorm(x, mean = 1000, sd = sd_W), from = 50, to = 150)
curve(dnorm(x, mean = 1000, sd = sd_W), from = 0, to = 2000)
lines(density(stat), lty = 2)
exp_W
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150)
lines(density(stat), lty = 2)
shapiro.test(stat)
?shapiro.test
stat <- vector()
for (i in 1:100) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
shapiro.test(stat)
stat <- vector()
for (i in 1:2) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
shapiro.test(stat)
for (i in 1:3) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
shapiro.test(stat)
stat <- vector()
for (i in 1:3) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
shapiro.test(stat)
stat <- vector()
for (i in 1:5000) {
random_ranks <- sample(length(vot1971$Rank))
W_random <- sum(random_ranks[1:10])
# There are 10 t's
stat[i] <- W_random
}
shapiro.test(stat)
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150)
lines(density(stat), lty = 2)
set.seed(0)
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150, xlab = 'VOT', ylab = 'Density', main = 'Random Simulated VOT')
legend(210, 0.015, legend = levels('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(210, 0.015, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(140, 0.030, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(120, 0.030, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(110, 0.030, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
curve(dnorm(x, mean = exp_W, sd = sd_W), from = 50, to = 150, xlab = 'VOT', ylab = 'Density', main = 'Random Simulated VOT')
lines(density(stat), lty = 2)
legend(110, 0.030, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(110, 0.033, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
legend(110, 0.035, legend = c('Normal Curve', 'Random Simulation'), lty = 1:2)
install.packages(c("energy", "car"))
library(energy)
library(car)
data(ldt)
attach(ldt)
plot(Length, Mean_RT, main = "Scatter plot of word length and mean reaction times")
plot(Mean_RT ~ Length)
m <- lm(Mean_RT ~ Length)
abline(m)
ggplot(ldt, aes(x = Length, y = Mean_RT)) + geom_point(shape = 1, size = 3) + stat_smooth(method = lm)
cor(Mean_RT, Length)
Mean_RT_1 <- Mean_RT[Mean_RT < 1200]
Length_1 <- Length[Mean_RT < 1200]
m1 <- lm(Mean_RT_1 ~ Length_1)
abline(m1, lty = 2)
abline(m1, lty = 2)
mvnorm.etest(cbind(Length_1, Mean_RT_1))
set.seed(0)
mvnorm.etest(cbind(Length_1, Mean_RT_1))
set.seed(0)
mvnorm.etest(cbind(Length_1, Mean_RT_1))
shapiro.test(stat)
ncvTest(m1)
durbinWatsonTest(m1)
cor.test(Length_1, Mean_RT_1, alternative = "greater")
hist(Length)
hist(Mean_RT)
IQR(Mean_RT)
sd(Length)
m$coefficients
Mean_RT.z = scale(Mean_RT)[, 1]
library(Rling)
plot(Mean_RT~Length,xlim=c(0,15),ylim=c(400,1600))
lines(c(0,20),c(mean(Mean_RT),mean(Mean_RT)))
lines(c(mean(Length),mean(Length)), c(0,2000))
m <- lm(Mean_RT~Length)  # linear model
abline(m)
m$coefficients  # shows the zero intercept and the slope of the line
cor(Mean_RT,Length)  # compute the correlation
Mean_RT.z = scale(Mean_RT)[,1]  # z = (x-mu)/sd  : data are centered around 0
Length.z = scale(Length)[,1]    #                : and are in standard devation units
plot(Mean_RT.z~Length.z)
lines(c(-5,5),c(0,0))
lines(c(0,0),c(-5,5))
lines(c(-5,5),c(-5,5),lty=2)
m2 <- lm(Mean_RT.z~Length.z)
abline(m2)
m2$coefficients
plot(Mean_RT.z,Mean_RT.z)  # identity
cor(Mean_RT.z,Mean_RT.z)
plot(Mean_RT.z,-Mean_RT.z)  # a perfect negative correlation
cor(Mean_RT.z,-Mean_RT.z)
mysd = 3.5   # play with different values of this on the code below
noise1 = rnorm(length(Mean_RT),sd=mysd)  # use Gausian noise - normal distribution
noise2 = rnorm(length(Mean_RT),sd=0)  # can play with different amounts for different groups
RT1 <- Mean_RT.z + noise1  # if noise = 0 then we have a correlation of 1
RT2 <- Mean_RT.z + noise2
plot(RT1~RT2,xlim=c(-5,5),ylim=c(-5,5))  # plot the correlation
R.value <- cor(RT1, RT2)
text(4,-4, paste("r = ",signif(R.value,3)))
m=lm(RT1 ~ RT2)
abline(m)
summary(m)
